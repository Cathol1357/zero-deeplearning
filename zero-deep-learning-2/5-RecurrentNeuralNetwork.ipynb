{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6865c593-53f3-4419-a546-b0c703d328a5",
   "metadata": {},
   "source": [
    "# 5章　リカレントニューラルネットワーク（RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27587299-25d7-4661-a8c0-fbdd281cff69",
   "metadata": {},
   "source": [
    "RNNは、ループする経路を持つことが特徴。データが循環することにより、過去の情報を記憶しながら最新のデータへと更新することができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eacd57-e38c-4150-b282-3e1d466b3ff7",
   "metadata": {},
   "source": [
    "* ## RNNレイヤで行われている計算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc184e-24cd-441b-bc60-8dc100957071",
   "metadata": {},
   "source": [
    "$$ \\textbf{h}_t = \\tanh (\\textbf{h}_{h-1} \\textbf{W}_h + \\textbf{x}_t \\textbf{W}_x + \\textbf{b})$$\n",
    "\n",
    "ただし、tanhの第一項は前のRNNレイヤからの入力、第二項と第三項は現在の時系列データからの入力を表す。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf042b-09d2-4a52-8c3b-ef9aad2a4818",
   "metadata": {},
   "source": [
    "### 【注意】ここでいう時系列データ$\\textbf{x}_t$は、時間変化しているわけではないことに注意。<br/>例えば、'This is a pen'という時系列データがあったら、$x_0 = $This、$x_1 = $is、$x_2 =$a、、、、といった具合になる。（この添字がtになっている）\n",
    "### 物理の記法では時間変化を表す記法なので、混乱しやすい。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b552457a-382f-44ea-bd6c-1b69f31517bc",
   "metadata": {},
   "source": [
    "## 5.3.1 RNNレイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1320bc-a6a7-4ab6-b3a9-38f360b9b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RNN :\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        # 一つ目の要素に入力データに対する勾配、二つ目の要素に前のRNNレイヤに対する勾配を格納\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)] \n",
    "        self.cache = None # 逆伝播の計算時に使用する中間データ\n",
    "\n",
    "\n",
    "    def forward(self, x, h, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b # 式のかっこの中を計算\n",
    "        h_next = np.tanh(t)\n",
    "\n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "\n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "\n",
    "        dt = dh_next * (1 - h_next**2) # tanhの微分と前のレイヤからの出力をかける\n",
    "        db = np.sum(dt, axis=0)\n",
    "        dWh = np.dot(h_prev.T, dt)\n",
    "        dh_prev = np.dot(dt, Wh.T)\n",
    "        dWx = np.dot(x.T, dt)\n",
    "        dx = np.dot(dt, Wx.T)\n",
    "\n",
    "        # 勾配を保存しておく\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "\n",
    "        return dx, dh_prev\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
